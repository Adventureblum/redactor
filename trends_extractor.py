#!/usr/bin/env python3
"""
Script d'extraction Google Trends avec pytrends
Inclut gestion d'erreurs, rate limiting et sauvegarde des donn√©es
"""

import pandas as pd
import time
import json
from datetime import datetime
from pytrends.request import TrendReq
import random

class TrendsExtractor:
    def __init__(self, language='fr', timezone=60):
        """
        Initialise l'extracteur de tendances
        
        Args:
            language (str): Code langue (fr, en, etc.)
            timezone (int): Timezone offset
        """
        self.pytrends = TrendReq(hl=language, tz=timezone)
        self.results = {}
        
    def extract_keyword_data(self, keyword, timeframe='today 12-m', geo='FR'):
        """
        Extrait toutes les donn√©es disponibles pour un mot-cl√©
        
        Args:
            keyword (str): Mot-cl√© √† analyser
            timeframe (str): P√©riode d'analyse
            geo (str): Zone g√©ographique
        """
        print(f"üîç Extraction des donn√©es pour: '{keyword}'")
        
        try:
            # Construction de la requ√™te
            self.pytrends.build_payload([keyword], timeframe=timeframe, geo=geo)
            
            # 1. √âvolution dans le temps
            print("  üìä R√©cup√©ration de l'√©volution temporelle...")
            interest_time = self.pytrends.interest_over_time()
            
            # 2. Int√©r√™t par r√©gion
            print("  üó∫Ô∏è  R√©cup√©ration des donn√©es g√©ographiques...")
            try:
                interest_region = self.pytrends.interest_by_region(resolution='CITY')
            except Exception as e:
                print(f"    ‚ö†Ô∏è  Donn√©es r√©gionales non disponibles: {str(e)}")
                interest_region = pd.DataFrame()
            
            # 3. Requ√™tes li√©es
            print("  üîó R√©cup√©ration des requ√™tes li√©es...")
            try:
                related_queries = self.pytrends.related_queries()
            except Exception as e:
                print(f"    ‚ö†Ô∏è  Requ√™tes li√©es non disponibles: {str(e)}")
                related_queries = {}
            
            # 4. Sujets li√©s
            print("  üìö R√©cup√©ration des sujets li√©s...")
            try:
                related_topics = self.pytrends.related_topics()
            except Exception as e:
                print(f"    ‚ö†Ô∏è  Sujets li√©s non disponibles: {str(e)}")
                related_topics = {}
            
            # 5. Suggestions (avec gestion d'erreur)
            print("  üí° R√©cup√©ration des suggestions...")
            try:
                suggestions = self.pytrends.suggestions(keyword=keyword)
            except Exception as e:
                print(f"    ‚ö†Ô∏è  Suggestions non disponibles: {str(e)}")
                suggestions = []
            
            # Stockage des r√©sultats
            self.results[keyword] = {
                'timestamp': datetime.now().isoformat(),
                'interest_over_time': interest_time,
                'interest_by_region': interest_region,
                'related_queries': related_queries,
                'related_topics': related_topics,
                'suggestions': suggestions,
                'metadata': {
                    'timeframe': timeframe,
                    'geo': geo,
                    'keyword': keyword
                }
            }
            
            print(f"  ‚úÖ Extraction termin√©e pour '{keyword}'")
            return True
            
        except Exception as e:
            print(f"  ‚ùå Erreur lors de l'extraction de '{keyword}': {str(e)}")
            return False
    
    def extract_multiple_keywords(self, keywords, delay_range=(2, 5)):
        """
        Extrait les donn√©es pour plusieurs mots-cl√©s avec d√©lais
        
        Args:
            keywords (list): Liste des mots-cl√©s
            delay_range (tuple): Range de d√©lai entre requ√™tes (min, max)
        """
        print(f"üöÄ D√©but de l'extraction pour {len(keywords)} mots-cl√©s")
        
        successful = 0
        for i, keyword in enumerate(keywords, 1):
            print(f"\n[{i}/{len(keywords)}]", end=" ")
            
            if self.extract_keyword_data(keyword):
                successful += 1
            
            # D√©lai al√©atoire pour √©viter le rate limiting
            if i < len(keywords):
                delay = random.uniform(*delay_range)
                print(f"  ‚è≥ Pause de {delay:.1f}s avant la prochaine requ√™te...")
                time.sleep(delay)
        
        print(f"\n‚ú® Extraction termin√©e: {successful}/{len(keywords)} r√©ussies")
    
    def display_summary(self, keyword):
        """Affiche un r√©sum√© des donn√©es extraites"""
        if keyword not in self.results:
            print(f"‚ùå Aucune donn√©e trouv√©e pour '{keyword}'")
            return
        
        data = self.results[keyword]
        print(f"\nüìã R√âSUM√â POUR '{keyword.upper()}'")
        print("=" * 50)
        
        # √âvolution temporelle
        interest_time = data['interest_over_time']
        if not interest_time.empty:
            avg_interest = interest_time[keyword].mean()
            max_interest = interest_time[keyword].max()
            print(f"üìä Int√©r√™t moyen: {avg_interest:.1f}/100")
            print(f"üìà Pic d'int√©r√™t: {max_interest}/100")
        
        # Top r√©gions
        interest_region = data['interest_by_region']
        if not interest_region.empty:
            top_regions = interest_region.nlargest(5, keyword)
            print(f"\nüèÜ TOP 5 R√âGIONS:")
            for region, score in top_regions.iterrows():
                print(f"   ‚Ä¢ {region}: {score[keyword]}/100")
        
        # Requ√™tes li√©es
        related_queries = data['related_queries']
        if related_queries and keyword in related_queries:
            if 'top' in related_queries[keyword] and related_queries[keyword]['top'] is not None:
                print(f"\nüîó TOP REQU√äTES LI√âES:")
                top_queries = related_queries[keyword]['top'].head(5)
                for idx, row in top_queries.iterrows():
                    print(f"   ‚Ä¢ {row['query']}: {row['value']}/100")
            
            if 'rising' in related_queries[keyword] and related_queries[keyword]['rising'] is not None:
                print(f"\nüöÄ REQU√äTES EN CROISSANCE:")
                rising_queries = related_queries[keyword]['rising'].head(5)
                for idx, row in rising_queries.iterrows():
                    growth = row['value'] if row['value'] != 'Breakout' else '+1000%'
                    print(f"   ‚Ä¢ {row['query']}: {growth}")
    
    def save_to_files(self, keyword, output_dir='./trends_data'):
        """Sauvegarde les donn√©es dans des fichiers"""
        import os
        
        if keyword not in self.results:
            print(f"‚ùå Aucune donn√©e √† sauvegarder pour '{keyword}'")
            return
        
        # Cr√©er le dossier de sortie
        os.makedirs(output_dir, exist_ok=True)
        
        data = self.results[keyword]
        safe_keyword = keyword.replace(' ', '_').replace('/', '_')
        
        # Sauvegarder chaque type de donn√©es
        if not data['interest_over_time'].empty:
            data['interest_over_time'].to_csv(f"{output_dir}/{safe_keyword}_evolution.csv")
        
        if not data['interest_by_region'].empty:
            data['interest_by_region'].to_csv(f"{output_dir}/{safe_keyword}_regions.csv")
        
        # Sauvegarder les m√©tadonn√©es et requ√™tes li√©es en JSON
        json_data = {
            'metadata': data['metadata'],
            'related_queries': self._serialize_related_data(data['related_queries']),
            'related_topics': self._serialize_related_data(data['related_topics']),
            'suggestions': data['suggestions']
        }
        
        with open(f"{output_dir}/{safe_keyword}_metadata.json", 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Donn√©es sauvegard√©es dans {output_dir}/")
    
    def _serialize_related_data(self, data):
        """Convertit les DataFrames en dictionnaires pour la s√©rialisation JSON"""
        if not data:
            return None
        
        result = {}
        for keyword, related_data in data.items():
            result[keyword] = {}
            for category, df in related_data.items():
                if df is not None and not df.empty:
                    result[keyword][category] = df.to_dict('records')
                else:
                    result[keyword][category] = None
        return result


def main():
    """Fonction principale - exemple d'utilisation"""
    
    # Initialisation
    extractor = TrendsExtractor(language='fr', timezone=60)
    
    # Mots-cl√©s √† analyser (commencez petit pour tester)
    keywords_test = [
        'formation python',
        'apprendre javascript',
        'cours html css'
    ]
    
    # Extraction des donn√©es
    print("üéØ EXTRACTION GOOGLE TRENDS")
    print("=" * 40)
    
    extractor.extract_multiple_keywords(keywords_test)
    
    # Affichage des r√©sultats
    for keyword in keywords_test:
        extractor.display_summary(keyword)
        extractor.save_to_files(keyword)
        print("\n" + "-" * 60)


if __name__ == "__main__":
    main()